{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting imdb_pro_spider_for_boxoffice.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile imdb_pro_spider_for_boxoffice.py\n",
    "import requests,re,os,sqlite3,sys,time,json\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import NavigableString\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imdb_pro_config import *\n",
    "from urllib.parse import urljoin\n",
    "sys.path.append('/home/guijideanhao/pyproject/scrapy_toolv2')\n",
    "from html_downloader import html_downloader\n",
    "from log_manager import log_manager\n",
    "\n",
    "class imdb_pro_spider():\n",
    "    '''\n",
    "    spider for https://pro.imdb.com/\n",
    "    \n",
    "    Attributes:\n",
    "        cookies (dict): cookies\n",
    "        headers (dict): headers\n",
    "        session (object): requests Session() object\n",
    "        log_manager (object)\n",
    "        success_ttid (list)\n",
    "        error_ttid (list)\n",
    "        table_name (str): the table save box office\n",
    "        db_path (str): the path of database\n",
    "        conn (object): the sqlite3 connection object\n",
    "    '''\n",
    "    def __init__(self, cookies_file, headers_file,table_name, db_path, log_filepath='imdb_pro.txt'):\n",
    "        '''\n",
    "        Args:\n",
    "            cookies_file (str): full cookies_file path in txt format\n",
    "            headers_file (str): full headers_file path in txt format\n",
    "            table_name (str): the table save box office\n",
    "            db_path (str): the path of database\n",
    "            log_filepath (str): full path of log file\n",
    "        '''\n",
    "        self.cookies = self.gen_cookies(cookies_file)\n",
    "        self.headers_file = headers_file\n",
    "        self.session = requests.Session()\n",
    "        self.log_manager = log_manager(log_filepath)\n",
    "        # replicate list\n",
    "        self.success_ttid = self.log_manager.get_info_list(success_tag='SUCCESS')\n",
    "        self.error_ttid = self.log_manager.get_info_list(success_tag='ERROR')\n",
    "        \n",
    "        self.table_name = table_name\n",
    "        self.db_path = db_path\n",
    "        self.conn = sqlite3.connect(self.db_path)\n",
    "        \n",
    "    def gen_cookies(self, cookies_file):\n",
    "        '''\n",
    "        Args:\n",
    "            cookies_file (str): full cookies_file path in txt format\n",
    "        \n",
    "        Returns:\n",
    "            dict: cookies dict\n",
    "        '''\n",
    "        cookies = {}\n",
    "        with open(cookies_file, 'r') as f:\n",
    "            cookies_str = f.read()\n",
    "        list_cookies = cookies_str.split(';')\n",
    "\n",
    "        for i in list_cookies:\n",
    "            name,value=i.strip().split('=',1)\n",
    "            cookies[name] = value\n",
    "        return cookies\n",
    "    def gen_headers(self, headers_file, ttid):\n",
    "        '''\n",
    "        Args:\n",
    "            headers_file (str): full headers_file path in txt format\n",
    "        \n",
    "        Returns:\n",
    "            dict: headers dict\n",
    "        '''\n",
    "        headers = {}\n",
    "        with open(headers_file, 'r') as f:\n",
    "            for i in f.readlines():\n",
    "                name,value = i.strip().split(':',1)\n",
    "                headers[name] = value.strip()\n",
    "        headers['Referer'] = 'https://pro.imdb.com/title/{}/boxoffice'.format(ttid)\n",
    "        return headers\n",
    "    def download_page(self, ttid):\n",
    "        '''\n",
    "        download html page\n",
    "        \n",
    "        Args:\n",
    "            ttid (str): film ttid\n",
    "        \n",
    "        Returns:\n",
    "            None or Response object: if fail return None, else response object\n",
    "\n",
    "        '''\n",
    "        url = 'https://pro.imdb.com/title/{}/boxoffice/_ajax'.format(ttid)\n",
    "        headers = self.gen_headers(self.headers_file,ttid)\n",
    "        res = self.session.get(url=url, cookies=self.cookies, headers=headers)\n",
    "        if res.status_code == 200:\n",
    "            return res\n",
    "        else:\n",
    "            return None\n",
    "    def parse_page_boxoffice(self, res_content, ttid):\n",
    "        '''\n",
    "        parse page to gain box office data\n",
    "        \n",
    "        Args:\n",
    "            res_content (binary): web page binary\n",
    "            ttid (str): film ttid\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if successfully gain data\n",
    "            df: if gain data return data\n",
    "            \n",
    "        to do:\n",
    "            * add a empty list\n",
    "            * add a used list\n",
    "            * add an error list\n",
    "        '''\n",
    "        soup = BeautifulSoup(res_content, 'html.parser')\n",
    "        empty_table = soup.find('span', {'class':'empty_mojo_table'})\n",
    "        box_office_mojo = soup.find('table', {'id':'box_office_mojo'})\n",
    "        if empty_table:\n",
    "            self.log_manager.write_log(info=ttid,info_type='no data',add_to_list=self.success_ttid)\n",
    "            return True,\n",
    "        elif not box_office_mojo:\n",
    "            # todo\n",
    "            # add a list of error print add to list function\n",
    "            print('ERROR: {}'.format(ttid))\n",
    "            self.log_manager.write_log(info=ttid,info_type='log',success=False)\n",
    "            return False,\n",
    "        else:\n",
    "            df = self.parse_table_boxoffice(box_office_mojo, ttid)\n",
    "            # todo\n",
    "            # add a list of used ttid print congratulation\n",
    "            return True, df\n",
    "            \n",
    "    def parse_table_boxoffice(self, box_office_mojo, ttid):\n",
    "        '''\n",
    "        Transform the table in the website to dataframe\n",
    "        \n",
    "        Args:\n",
    "            box_office_mojo (BeautifulSoup object): table object\n",
    "            \n",
    "        Returns:\n",
    "            dataframe\n",
    "        '''\n",
    "        dict_for_pandas = {'date1':[], 'date2':[], 'date3':[], 'date4':[],\n",
    "                           'single_day_gross':[], 'single_day_gross_rank':[],\n",
    "                          'change_yesterday':[], 'change_last_week':[],\n",
    "                          'theaters':[], 'avg_per_theaters':[], 'gross_since_release':[]}\n",
    "        list_tmp_dict = []\n",
    "        trs = box_office_mojo.find_all('tr')\n",
    "        for i in trs:\n",
    "            tmp_dict = {}\n",
    "            if i.has_attr('class'):\n",
    "                if 'heading' in i['class']:\n",
    "                    continue\n",
    "            tds = i.find_all('td')\n",
    "            # element 0 dates\n",
    "            tmp_dict['date1'] = tds[0].get('data-sort-value')\n",
    "            dates = tds[0].div.find_all('p', {'class':'a-spacing-mini'})\n",
    "            tmp_dict['date2'] = dates[0].get_text()\n",
    "            tmp_dict['date3'] = dates[1].get_text()\n",
    "            if i.has_attr('class'):\n",
    "                if 'box_office_mojo_special_occasion_row' in i.get('class'):\n",
    "                    tmp_dict['date4'] = dates[2].get_text()\n",
    "            # element 1 single day gross ($)\n",
    "            tmp_dict['single_day_gross'] = tds[1].get('data-sort-value')\n",
    "            sdgs = tds[1].div.find_all('p', {'class':'a-spacing-mini'})\n",
    "            tmp_dict['single_day_gross_rank'] = sdgs[0].get_text()\n",
    "            # element 2 change yesterday (%)\n",
    "            tmp_dict['change_yesterday'] = tds[2].get('data-sort-value')\n",
    "            # element 3 change_last_week (%)\n",
    "            tmp_dict['change_last_week'] = tds[3].get('data-sort-value')\n",
    "            # element 4 theaters\n",
    "            tmp_dict['theaters'] = tds[4].get('data-sort-value')\n",
    "            # element 5 avg_per_theaters ($)\n",
    "            tmp_dict['avg_per_theaters'] = tds[5].get('data-sort-value')\n",
    "            # element 6 gross_since_release ($)\n",
    "            tmp_dict['gross_since_release'] = tds[6].get('data-sort-value')\n",
    "            \n",
    "            list_tmp_dict.append(tmp_dict)\n",
    "        for k in dict_for_pandas.keys():\n",
    "            for l in list_tmp_dict:\n",
    "                dict_for_pandas[k].append(l.get(k))\n",
    "        df = pd.DataFrame(dict_for_pandas)\n",
    "        rearrange_col = ['ttid'] + df.columns.tolist()\n",
    "        df['ttid'] = ttid\n",
    "        df = df[rearrange_col]\n",
    "        return df\n",
    "    def parse_save_ttid_list(self, list_ttid, teststop=-1):\n",
    "        '''\n",
    "        parse and save\n",
    "        Args:\n",
    "            list_ttid (list)\n",
    "            teststop (int): for text\n",
    "        '''\n",
    "        for i in list_ttid:\n",
    "            if teststop == 0:\n",
    "                print('test end')\n",
    "                break\n",
    "            # replicate check\n",
    "            if i in self.success_ttid or i in self.error_ttid:\n",
    "                continue\n",
    "            # download page\n",
    "            try:\n",
    "                res = self.download_page(i)\n",
    "                if res == None:\n",
    "                    self.log_manager.write_log(success=False, info_type='server forbid', info=i, add_to_list=self.error_ttid)\n",
    "                    break\n",
    "            except:\n",
    "                self.log_manager.write_log(success=False,info_type='download unknown', info=i, add_to_list=self.error_ttid)\n",
    "                break\n",
    "            # parse page\n",
    "            try:\n",
    "                success,*df = self.parse_page_boxoffice(res.content, i)\n",
    "                if success:\n",
    "                    if df == []:\n",
    "                        time.sleep(60)\n",
    "                        continue\n",
    "                else:\n",
    "                    break\n",
    "            except:\n",
    "                self.log_manager.write_log(info=i, success=False, info_type='parse_unknown',add_to_list=self.error_ttid)\n",
    "                continue\n",
    "                \n",
    "            # save df\n",
    "            try:\n",
    "                df[0].to_sql(name=self.table_name,con=self.conn,if_exists='append',index=False)\n",
    "                self.log_manager.write_log(info=i, add_to_list=self.success_ttid)\n",
    "                if teststop>0:\n",
    "                    teststop = teststop -1\n",
    "                time.sleep(60)\n",
    "            except:\n",
    "                self.log_manager.write_log(info=i, success=False, info_type='db', add_to_list=self.error_ttid)\n",
    "                time.sleep(60)\n",
    "                continue\n",
    "        print('mission complete')\n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    conn = sqlite3.connect('/home/guijideanhao/pyproject/imdb/imdb_data/imdb_film.db')\n",
    "\n",
    "    df1 = pd.read_sql('select * from {}'.format('film_list'), conn)\n",
    "\n",
    "    def year_to_int(value):\n",
    "        s_tmp = re.search(r'\\d+',value)\n",
    "        if s_tmp:\n",
    "            tmp = s_tmp.group()\n",
    "            tmp = np.int(tmp)\n",
    "        else:\n",
    "            tmp = np.nan\n",
    "        return tmp\n",
    "    df1['year'] = df1['year'].apply(year_to_int)\n",
    "    df1 = df1[df1['year']==2018]\n",
    "    ttids = df1['ttid'].values.tolist()\n",
    "    \n",
    "    test = imdb_pro_spider(cookies_file=FILE_COOKIES,headers_file=FILE_HEADERS,table_name=TABLE_NAME_BOXOFFICE,db_path=FILE_DABABASE)\n",
    "    test.parse_save_ttid_list(ttids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mhtml_downloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchina\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mworld\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mqiyeurl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'http://localhost:8000'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mxiciurl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'http://www.xicidaili.com/wn/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m           ~/pyproject/scrapy_toolv2/html_downloader.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_downloader?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. func test\n",
    "## 1.1 download_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pro.imdb.com/title/tt1706620/boxoffice/_ajax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'table_name' and 'db_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f513243c0ae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb_pro_spider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cookies.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'headers.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'table_name' and 'db_path'"
     ]
    }
   ],
   "source": [
    "t1 = imdb_pro_spider('cookies.txt', 'headers.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = t2.download_page(ttid='tt4779682')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.html', 'wb+') as f:\n",
    "    f.write(r1.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttid2 = 'tt6856242'\n",
    "r2 = t1.download_page(ttid=ttid2)\n",
    "r2.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test2.html', 'wb+') as f:\n",
    "    f.write(r2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 test func: parse_page_boxoffice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "success1, *df1 = t2.parse_page_boxoffice(r1.content, 'tt4779682')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ttid</th>\n",
       "      <th>date1</th>\n",
       "      <th>date2</th>\n",
       "      <th>date3</th>\n",
       "      <th>date4</th>\n",
       "      <th>single_day_gross</th>\n",
       "      <th>single_day_gross_rank</th>\n",
       "      <th>change_yesterday</th>\n",
       "      <th>change_last_week</th>\n",
       "      <th>theaters</th>\n",
       "      <th>avg_per_theaters</th>\n",
       "      <th>gross_since_release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20180810</td>\n",
       "      <td>Fri, Aug 10, 2018\\n</td>\n",
       "      <td>Day 1\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>16604015</td>\n",
       "      <td>$16,604,015\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4118</td>\n",
       "      <td>4032</td>\n",
       "      <td>16604015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20180811</td>\n",
       "      <td>Sat, Aug 11, 2018\\n</td>\n",
       "      <td>Day 2\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>16277249</td>\n",
       "      <td>$16,277,249\\n</td>\n",
       "      <td>-1968</td>\n",
       "      <td>None</td>\n",
       "      <td>4118</td>\n",
       "      <td>3952</td>\n",
       "      <td>32881264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20180812</td>\n",
       "      <td>Sun, Aug 12, 2018\\n</td>\n",
       "      <td>Day 3\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>12520931</td>\n",
       "      <td>$12,520,931\\n</td>\n",
       "      <td>-23078</td>\n",
       "      <td>None</td>\n",
       "      <td>4118</td>\n",
       "      <td>3040</td>\n",
       "      <td>45402195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20180813</td>\n",
       "      <td>Mon, Aug 13, 2018\\n</td>\n",
       "      <td>Day 4\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>4552992</td>\n",
       "      <td>$4,552,992\\n</td>\n",
       "      <td>-63637</td>\n",
       "      <td>None</td>\n",
       "      <td>4118</td>\n",
       "      <td>1105</td>\n",
       "      <td>49955187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20180814</td>\n",
       "      <td>Tue, Aug 14, 2018\\n</td>\n",
       "      <td>Day 5\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>6036127</td>\n",
       "      <td>$6,036,127\\n</td>\n",
       "      <td>32574</td>\n",
       "      <td>None</td>\n",
       "      <td>4118</td>\n",
       "      <td>1465</td>\n",
       "      <td>55991314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20181028</td>\n",
       "      <td>Sun, Oct 28, 2018\\n</td>\n",
       "      <td>Day 80\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>27658</td>\n",
       "      <td>$27,658\\n</td>\n",
       "      <td>-35705</td>\n",
       "      <td>-32279</td>\n",
       "      <td>168</td>\n",
       "      <td>164</td>\n",
       "      <td>142976043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20181029</td>\n",
       "      <td>Mon, Oct 29, 2018\\n</td>\n",
       "      <td>Day 81\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>6998</td>\n",
       "      <td>$6,998\\n</td>\n",
       "      <td>-74699</td>\n",
       "      <td>-27990</td>\n",
       "      <td>168</td>\n",
       "      <td>41</td>\n",
       "      <td>142983041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20181030</td>\n",
       "      <td>Tue, Oct 30, 2018\\n</td>\n",
       "      <td>Day 82\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>6776</td>\n",
       "      <td>$6,776\\n</td>\n",
       "      <td>-3173</td>\n",
       "      <td>-41222</td>\n",
       "      <td>168</td>\n",
       "      <td>40</td>\n",
       "      <td>142989817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20181031</td>\n",
       "      <td>Wed, Oct 31, 2018\\n</td>\n",
       "      <td>Day 83\\n</td>\n",
       "      <td>Halloween\\n</td>\n",
       "      <td>7950</td>\n",
       "      <td>$7,950\\n</td>\n",
       "      <td>17325</td>\n",
       "      <td>-11775</td>\n",
       "      <td>168</td>\n",
       "      <td>47</td>\n",
       "      <td>142997767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20181101</td>\n",
       "      <td>Thu, Nov 1, 2018\\n</td>\n",
       "      <td>Day 84\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>8089</td>\n",
       "      <td>$8,089\\n</td>\n",
       "      <td>1748</td>\n",
       "      <td>-23869</td>\n",
       "      <td>168</td>\n",
       "      <td>48</td>\n",
       "      <td>143005856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ttid     date1                 date2      date3         date4  \\\n",
       "0   tt4779682  20180810   Fri, Aug 10, 2018\\n    Day 1\\n          None   \n",
       "1   tt4779682  20180811   Sat, Aug 11, 2018\\n    Day 2\\n          None   \n",
       "2   tt4779682  20180812   Sun, Aug 12, 2018\\n    Day 3\\n          None   \n",
       "3   tt4779682  20180813   Mon, Aug 13, 2018\\n    Day 4\\n          None   \n",
       "4   tt4779682  20180814   Tue, Aug 14, 2018\\n    Day 5\\n          None   \n",
       "..        ...       ...                   ...        ...           ...   \n",
       "79  tt4779682  20181028   Sun, Oct 28, 2018\\n   Day 80\\n          None   \n",
       "80  tt4779682  20181029   Mon, Oct 29, 2018\\n   Day 81\\n          None   \n",
       "81  tt4779682  20181030   Tue, Oct 30, 2018\\n   Day 82\\n          None   \n",
       "82  tt4779682  20181031   Wed, Oct 31, 2018\\n   Day 83\\n   Halloween\\n   \n",
       "83  tt4779682  20181101    Thu, Nov 1, 2018\\n   Day 84\\n          None   \n",
       "\n",
       "   single_day_gross single_day_gross_rank change_yesterday change_last_week  \\\n",
       "0          16604015         $16,604,015\\n             None             None   \n",
       "1          16277249         $16,277,249\\n            -1968             None   \n",
       "2          12520931         $12,520,931\\n           -23078             None   \n",
       "3           4552992          $4,552,992\\n           -63637             None   \n",
       "4           6036127          $6,036,127\\n            32574             None   \n",
       "..              ...                   ...              ...              ...   \n",
       "79            27658             $27,658\\n           -35705           -32279   \n",
       "80             6998              $6,998\\n           -74699           -27990   \n",
       "81             6776              $6,776\\n            -3173           -41222   \n",
       "82             7950              $7,950\\n            17325           -11775   \n",
       "83             8089              $8,089\\n             1748           -23869   \n",
       "\n",
       "   theaters avg_per_theaters gross_since_release  \n",
       "0      4118             4032            16604015  \n",
       "1      4118             3952            32881264  \n",
       "2      4118             3040            45402195  \n",
       "3      4118             1105            49955187  \n",
       "4      4118             1465            55991314  \n",
       "..      ...              ...                 ...  \n",
       "79      168              164           142976043  \n",
       "80      168               41           142983041  \n",
       "81      168               40           142989817  \n",
       "82      168               47           142997767  \n",
       "83      168               48           143005856  \n",
       "\n",
       "[84 rows x 12 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO DATA: No box office chart for tt6856242\n"
     ]
    }
   ],
   "source": [
    "success2, *df2 = t1.parse_page_boxoffice(r2.content, ttid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 test class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the len of list: 2\n",
      "the len of list: 0\n"
     ]
    }
   ],
   "source": [
    "t2 = imdb_pro_spider(cookies_file=FILE_COOKIES,headers_file=FILE_HEADERS,table_name=TABLE_NAME_BOXOFFICE,db_path='test.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('/home/guijideanhao/pyproject/imdb/imdb_data/imdb_film.db')\n",
    "\n",
    "df1 = pd.read_sql('select * from {}'.format('film_list'), conn)\n",
    "\n",
    "def year_to_int(value):\n",
    "    s_tmp = re.search(r'\\d+',value)\n",
    "    if s_tmp:\n",
    "        tmp = s_tmp.group()\n",
    "        tmp = np.int(tmp)\n",
    "    else:\n",
    "        tmp = np.nan\n",
    "    return tmp\n",
    "df1['year'] = df1['year'].apply(year_to_int)\n",
    "df1 = df1[df1['year']==2018]\n",
    "ttids = df1['ttid'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tt4779682'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-05 17:38:59  SUCCESS  notype  tt1825683\n",
      "2020-07-05 17:40:00  SUCCESS  notype  tt1365519\n",
      "test end\n",
      "mission complete\n"
     ]
    }
   ],
   "source": [
    "t2.parse_save_ttid_list(ttids, teststop=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435, 12)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview_boxoffice = pd.read_sql('select * from {}'.format(TABLE_NAME_BOXOFFICE),test.conn)\n",
    "preview_boxoffice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ttid</th>\n",
       "      <th>date1</th>\n",
       "      <th>date2</th>\n",
       "      <th>date3</th>\n",
       "      <th>date4</th>\n",
       "      <th>single_day_gross</th>\n",
       "      <th>single_day_gross_rank</th>\n",
       "      <th>change_yesterday</th>\n",
       "      <th>change_last_week</th>\n",
       "      <th>theaters</th>\n",
       "      <th>avg_per_theaters</th>\n",
       "      <th>gross_since_release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20180810</td>\n",
       "      <td>Fri, Aug 10, 2018\\n</td>\n",
       "      <td>Day 1\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>16604015</td>\n",
       "      <td>$16,604,015\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4118</td>\n",
       "      <td>4032</td>\n",
       "      <td>16604015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20180811</td>\n",
       "      <td>Sat, Aug 11, 2018\\n</td>\n",
       "      <td>Day 2\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>16277249</td>\n",
       "      <td>$16,277,249\\n</td>\n",
       "      <td>-1968</td>\n",
       "      <td>None</td>\n",
       "      <td>4118</td>\n",
       "      <td>3952</td>\n",
       "      <td>32881264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20180812</td>\n",
       "      <td>Sun, Aug 12, 2018\\n</td>\n",
       "      <td>Day 3\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>12520931</td>\n",
       "      <td>$12,520,931\\n</td>\n",
       "      <td>-23078</td>\n",
       "      <td>None</td>\n",
       "      <td>4118</td>\n",
       "      <td>3040</td>\n",
       "      <td>45402195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20180813</td>\n",
       "      <td>Mon, Aug 13, 2018\\n</td>\n",
       "      <td>Day 4\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>4552992</td>\n",
       "      <td>$4,552,992\\n</td>\n",
       "      <td>-63637</td>\n",
       "      <td>None</td>\n",
       "      <td>4118</td>\n",
       "      <td>1105</td>\n",
       "      <td>49955187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt4779682</td>\n",
       "      <td>20180814</td>\n",
       "      <td>Tue, Aug 14, 2018\\n</td>\n",
       "      <td>Day 5\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>6036127</td>\n",
       "      <td>$6,036,127\\n</td>\n",
       "      <td>32574</td>\n",
       "      <td>None</td>\n",
       "      <td>4118</td>\n",
       "      <td>1465</td>\n",
       "      <td>55991314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ttid     date1                 date2     date3 date4 single_day_gross  \\\n",
       "0  tt4779682  20180810   Fri, Aug 10, 2018\\n   Day 1\\n  None         16604015   \n",
       "1  tt4779682  20180811   Sat, Aug 11, 2018\\n   Day 2\\n  None         16277249   \n",
       "2  tt4779682  20180812   Sun, Aug 12, 2018\\n   Day 3\\n  None         12520931   \n",
       "3  tt4779682  20180813   Mon, Aug 13, 2018\\n   Day 4\\n  None          4552992   \n",
       "4  tt4779682  20180814   Tue, Aug 14, 2018\\n   Day 5\\n  None          6036127   \n",
       "\n",
       "  single_day_gross_rank change_yesterday change_last_week theaters  \\\n",
       "0         $16,604,015\\n             None             None     4118   \n",
       "1         $16,277,249\\n            -1968             None     4118   \n",
       "2         $12,520,931\\n           -23078             None     4118   \n",
       "3          $4,552,992\\n           -63637             None     4118   \n",
       "4          $6,036,127\\n            32574             None     4118   \n",
       "\n",
       "  avg_per_theaters gross_since_release  \n",
       "0             4032            16604015  \n",
       "1             3952            32881264  \n",
       "2             3040            45402195  \n",
       "3             1105            49955187  \n",
       "4             1465            55991314  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preview_boxoffice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_boxoffice.to_csv('/home/guijideanhao/buffer/data_preview_boxoffice2018.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
